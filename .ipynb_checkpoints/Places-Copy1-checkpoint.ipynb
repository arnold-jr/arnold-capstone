{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#AmeniDC\n",
    "## See the cost of amenities in the District of Columbia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import simplejson as json\n",
    "import requests\n",
    "from requests import Request, Session\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "from urlparse import urljoin\n",
    "from collections import namedtuple\n",
    "import sqlite3\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#import geojson\n",
    "#from geojson import Feature, Point, FeatureCollection\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#OpenData.DC API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Get the property sale points from http://opendata.dc.gov/datasets/2acc75ccdd954267acecb8713b2b800a_28\n",
    "and store as a SQL database pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ediblepickle import checkpoint\n",
    "\n",
    "@checkpoint(key='prop_sales_json.csv', work_dir='data', refresh=False)\n",
    "def request_records():\n",
    "  url = 'http://opendata.dc.gov/datasets/2acc75ccdd954267acecb8713b2b800a_28.geojson'\n",
    "  with requests.Session() as s:\n",
    "    resp = s.get(url)\n",
    "    try:\n",
    "        resp.raise_for_status()\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print \"And you get an HTTPError:\", e.message\n",
    " \n",
    "\n",
    "  return resp.json()\n",
    "\n",
    "@checkpoint(key='prop_sales_dataframe.csv', work_dir='data', refresh=False)\n",
    "def build_records(resp_json):\n",
    "  row_dicts = []\n",
    "  for feats in resp_json['features']:\n",
    "    # Get all the property attributes\n",
    "    row = feats['properties']\n",
    "    row.update(feats['geometry'])\n",
    "    row_dicts.append(row)\n",
    "  return pd.DataFrame(row_dicts)\n",
    "\n",
    "if False:\n",
    "  resp_json = request_records()\n",
    "\n",
    "  df = build_records(resp_json)\n",
    "  keep_cols = [u'ABTLOTCODE',\n",
    "   u'ACCEPTCODE',\n",
    "   u'ADDRESS1',\n",
    "   u'ADDRESS2',\n",
    "   u'ANNUALTAX',\n",
    "   u'ASSESSMENT',\n",
    "   u'BASEBUILD',\n",
    "   u'BASELAND',\n",
    "   u'CAPCURR',\n",
    "   u'CAPPROP',\n",
    "   u'CAREOFNAME',\n",
    "   u'CITYSTZIP',\n",
    "   u'CLASS3',\n",
    "   u'CLASS3EX',\n",
    "   u'CLASSTYPE',\n",
    "   u'COOPUNITS',\n",
    "   u'DELCODE',\n",
    "   u'EXTRACTDAT',\n",
    "   u'HIGHNUMBER',\n",
    "   u'HSTDCODE',\n",
    "   u'LANDAREA',\n",
    "   u'LOT',\n",
    "   u'LOWNUMBER',\n",
    "   u'MIX1BLDPCT',\n",
    "   u'MIX1BLDVAL',\n",
    "   u'MIX1CLASS',\n",
    "   u'MIX1LNDPCT',\n",
    "   u'MIX1LNDVAL',\n",
    "   u'MIX1RATE',\n",
    "   u'MIX1TXTYPE',\n",
    "   u'MIX2BLDPCT',\n",
    "   u'MIX2BLDVAL',\n",
    "   u'MIX2CLASS',\n",
    "   u'MIX2LNDPCT',\n",
    "   u'MIX2LNDVAL',\n",
    "   u'MIX2RATE',\n",
    "   u'MIX2TXTYPE',\n",
    "   u'MIXEDUSE',\n",
    "   u'NBHD',\n",
    "   u'NEWIMPR',\n",
    "   u'NEWLAND',\n",
    "   u'NEWTOTAL',\n",
    "   u'OBJECTID',\n",
    "   u'OLDIMPR',\n",
    "   u'OLDLAND',\n",
    "   u'OLDTOTAL',\n",
    "   u'OWNERNAME',\n",
    "   u'OWNNAME2',\n",
    "   u'OWNOCCT',\n",
    "   u'PARTPART',\n",
    "   u'PCHILDCODE',\n",
    "   u'PHASEBUILD',\n",
    "   u'PHASECYCLE',\n",
    "   u'PHASELAND',\n",
    "   u'PREMISEADD',\n",
    "   u'PROPTYPE',\n",
    "   u'QDRNTNAME',\n",
    "   u'REASONCD',\n",
    "   u'SALEDATE',\n",
    "   u'SALEPRICE',\n",
    "   u'SALETYPE',\n",
    "   u'SQUARE',\n",
    "   u'SSL',\n",
    "   u'STREETCODE',\n",
    "   u'STREETNAME',\n",
    "   u'SUBNBHD',\n",
    "   u'SUFFIX',\n",
    "   u'TAXRATE',\n",
    "   u'TRIGROUP',\n",
    "   u'TXSALEDESC',\n",
    "   u'UNITNUMBER',\n",
    "   u'USECODE',\n",
    "   u'VACLNDUSE',\n",
    "   u'coordinates']\n",
    "\n",
    "  df.drop((c for c in df.columns.tolist() if c not in keep_cols),axis=1,inplace=True)\n",
    "  df['lat_lng'] = df['coordinates'].map(lambda row: str(row[1])+','+str(row[0]))\n",
    "  df['latitude'] = df['coordinates'].map(lambda row: row[1])\n",
    "  df['longitude'] = df['coordinates'].map(lambda row: row[0])\n",
    "  df.drop('coordinates',axis=1,inplace=True)\n",
    "  df.to_hdf('./data/df_wo_goog.hd5','df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "  df = pd.read_hdf('./data/df_wo_goog.hd5','df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Maps Places API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, property sale locations are queried for nearby amenities. API requests were made once offline and pickled. Data for each lat_lng pair were stored as dict. \n",
    "\n",
    "Create a df column showing amenity_price_rating numbers for the top 20 hits within 1000m of the property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_hdf('./data/df_w_amen.hd5','df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import simplejson as json\n",
    "from requests import Request, Session\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool\n",
    "from ediblepickle import checkpoint\n",
    "from requests_futures.sessions import FuturesSession\n",
    "from collections import namedtuple\n",
    "\n",
    "# Read in all API keys\n",
    "with open(\"../secrets/google_secrets.json.nogit\") as fh: \n",
    "  secrets = json.loads(fh.read())\n",
    "google_api_key = secrets['server_api_key']\n",
    "\n",
    "# Define amenity types of interest\n",
    "AMENITY_TYPES = ['bakery','bar','cafe','grocery_or_supermarket',\n",
    "  'movie_theater','park','pharmacy','restaurant','school','spa','subway_station']\n",
    "\n",
    "Place = namedtuple('Place',['name','lat_lng','rating','price_level'])\n",
    "\n",
    "def google_places_parser(sess,resp):\n",
    "  row_list = []\n",
    "  for r in resp.json()['results']:\n",
    "    name = r.get('name')\n",
    "    lat_lng = str(r['geometry']['location']['lat']) + ',' + str(r['geometry']['location']['lng'])\n",
    "    rating = r.get('rating')\n",
    "    price_level = r.get('price_level')\n",
    "    row_list.append(Place(name,lat_lng,rating,price_level))\n",
    "  resp.data = row_list\n",
    "\n",
    "\n",
    "def get_amenities(query_str, lat_lng_series):\n",
    "  ''' Given an amenity-type query string and an nd-array-like\n",
    "  lat_lng_series, return a list of list of results'''\n",
    "\n",
    "  search_url = \"https://maps.googleapis.com/maps/\" \\\n",
    "    \"api/place/nearbysearch/json\"\n",
    "  search_payload = {\"key\":google_api_key,\n",
    "                    \"radius\":1000,\n",
    "                    \"types\":query_str}\n",
    "  urls = (search_url+'?location='+lat_lng_str for lat_lng_str \n",
    "      in lat_lng_series)\n",
    "\n",
    "\n",
    "  session = FuturesSession(max_workers=7)\n",
    "  futures = [session.get(url,params=search_payload,\n",
    "                background_callback=google_places_parser) for url in urls]\n",
    "  \n",
    "  return [f.result().data for f in futures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python2.7/site-packages/pandas/io/pytables.py:2577: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->[u'ABTLOTCODE', u'ACCEPTCODE', u'ADDRESS1', u'ADDRESS2', u'CAREOFNAME', u'CITYSTZIP', u'CLASS3', u'CLASSTYPE', u'DELCODE', u'EXTRACTDAT', u'HIGHNUMBER', u'HSTDCODE', u'LOT', u'LOWNUMBER', u'MIX1CLASS', u'MIX1TXTYPE', u'MIX2CLASS', u'MIX2TXTYPE', u'MIXEDUSE', u'NBHD', u'OWNERNAME', u'OWNNAME2', u'PARTPART', u'PCHILDCODE', u'PHASECYCLE', u'PREMISEADD', u'PROPTYPE', u'QDRNTNAME', u'REASONCD', u'SALEDATE', u'SALETYPE', u'SQUARE', u'SSL', u'STREETCODE', u'STREETNAME', u'SUBNBHD', u'SUFFIX', u'TRIGROUP', u'TXSALEDESC', u'UNITNUMBER', u'USECODE', u'VACLNDUSE', 'lat_lng', 'bakery', 'bar', 'cafe', 'grocery_or_supermarket', 'movie_theater', 'park', 'pharmacy', 'restaurant', 'school', 'spa', 'subway_station']]\n",
      "\n",
      "  warnings.warn(ws, PerformanceWarning)\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "  amenity = AMENITY_TYPES[10]\n",
    "  df[amenity] = pd.Series(get_amenities(amenity,df['lat_lng']))\n",
    "  df.to_hdf('./data/df_w_amen.hd5','df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-d7c82a388059>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mAMENITY_TYPES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df[df['PROPTYPE']=='RESIDENTIAL-SINGLE FAMILY'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for p in df['bakery'][0]:\n",
    "  print p.name, p.rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(p.rating for p in df['bakery'][0] if p.rating)/sum(True for p in df['bakery'][0] if p.rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###When places have the same name, use the haversine formula to determine if they refer to the same place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "haversine(-77.020269,38.894629,-77.0325204,38.9039343)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import radians, cos, sin, asin, sqrt\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    km = 6367 * c\n",
    "    return km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[['SALEPRICE','SUBNBHD','bakery']].groupby('SUBNBHD').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "matplotlib.rcParams['savefig.dpi'] = 2 * matplotlib.rcParams['savefig.dpi']\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "def grid_score_plotter(cv,param):\n",
    "  cv_accuracy = pd.DataFrame.from_records(\n",
    "      [(score.parameters[param],\n",
    "        score.mean_validation_score)\n",
    "       for score in cv.grid_scores_],\n",
    "  columns=[param, 'accuracy'])\n",
    "\n",
    "  plt.plot(cv_accuracy[param], cv_accuracy.accuracy)\n",
    "  plt.xlabel(param)\n",
    "  plt.ylabel('accuracy')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ColumnSelectTransformer(BaseEstimator, TransformerMixin):\n",
    "  \"\"\"\n",
    "  Select columns of data from nd array\n",
    "  \"\"\"\n",
    "  def __init__(self, columns):\n",
    "    ''' columns must be list of strings '''\n",
    "    if type(columns) is list or type(columns) is str:\n",
    "      self.columns = columns\n",
    "    \n",
    "  def fit(self, X, y):\n",
    "    return self\n",
    "\n",
    "  def transform(self, X):\n",
    "    ''' Assume X is pandas dataframe'''\n",
    "    return X[self.columns]\n",
    "    \n",
    "class ShellTransformer(BaseEstimator, TransformerMixin):\n",
    "  '''Pass the fitted fitted_model into the init function\n",
    "  and predict during the transform step'''\n",
    "  def __init__(self,fitted_model):\n",
    "    self.fitted_model = fitted_model\n",
    "    pass\n",
    "  \n",
    "  def fit(self,X,y=None):\n",
    "    return self\n",
    "\n",
    "  def transform(self,X):\n",
    "    '''Here, X is a pandas DataFrame'''\n",
    "    return self.fitted_model.predict(X)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import linear_model\n",
    "from sklearn import cross_validation, grid_search\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "amen_pipe = Pipeline([\n",
    "    ('select', ColumnSelectTransformer('amenities_1000')),\n",
    "    ('vec', DictVectorizer(sparse=True)),\n",
    "    ('ridge', linear_model.Ridge()),\n",
    "])\n",
    "\n",
    "amen_model = grid_search.GridSearchCV( amen_pipe,\n",
    "                param_grid={'ridge__alpha':np.logspace(0.7,1.5,5)},\n",
    "                cv=cross_validation.ShuffleSplit(len(df.index), n_iter=20, \n",
    "                    test_size=0.2, random_state=42) )\n",
    "\n",
    "amen_model.fit(df,df['SALEPRICE'])\n",
    "grid_score_plotter(amen_model,'ridge__alpha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "lat_lng_pipe = Pipeline([\n",
    "    ('select',ColumnSelectTransformer(['latitude','longitude'])),\n",
    "    ('knn', neighbors.KNeighborsRegressor())\n",
    "  ])\n",
    "\n",
    "param_grid = {\"knn__n_neighbors\": range(3,20)}\n",
    "lat_lng_model = grid_search.GridSearchCV( lat_lng_pipe,\n",
    "                param_grid=param_grid,\n",
    "                cv=cross_validation.ShuffleSplit(len(df.index), n_iter=100, \n",
    "                    test_size=0.2,) )\n",
    "\n",
    "lat_lng_model.fit(df[['latitude','longitude']],df['SALEPRICE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in param_grid.keys():\n",
    "  grid_score_plotter(lat_lng_model,key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "amenity_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "lat_lng_model = grid_search.GridSearchCV( ensemble.RandomForestRegressor(n_jobs=-1),\n",
    "                param_grid={\"min_samples_leaf\": range(1,10)},\n",
    "                cv=cross_validation.ShuffleSplit(len(df.index), n_iter=20, \n",
    "                    test_size=0.2,) )\n",
    "\n",
    "lat_lng_model.fit(df[['latitude','longitude']],df['SALEPRICE'])\n",
    "grid_score_plotter(lat_lng_model,'min_samples_leaf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn import linear_model\n",
    "from sklearn import cross_validation, grid_search\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "amen_pipe = Pipeline([\n",
    "    ('select', ColumnSelectTransformer('amenities_1000')),\n",
    "    ('vec', DictVectorizer(sparse=True)),\n",
    "    ('ridge', linear_model.Ridge()),\n",
    "])\n",
    "\n",
    "amen_model = grid_search.GridSearchCV( amen_pipe,\n",
    "                param_grid={'ridge__alpha':np.logspace(0.7,1.5,5)},\n",
    "                cv=cross_validation.ShuffleSplit(len(df.index), n_iter=20, \n",
    "                    test_size=0.2, random_state=42) )\n",
    "\n",
    "amen_model.fit(df,df['SALEPRICE'])\n",
    "grid_score_plotter(amen_model,'ridge__alpha')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
